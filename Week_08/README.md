学习笔记

# 第15课 超越分库分表 - 数据库拆分与分库分表

### 1.为什么要做数据库拆分

- 从读写分离到数据库拆分
  - 主从结构解决了高可用，读扩展，但是单机容量不变，单机写性能无法解决
  - 提升容量-->分库分表，分布式，多个数据库，作为数据分片的集群提供服务
  - 降低单个节点的写压力
  - 提升整个系统的数据容量上限

### 2.数据库垂直拆分

- 垂直拆分 - 淘宝的服务化
  - 垂直分库分表=>分布式服务话=>微服务架构
- 拆库 
  - 将一个数据库，拆分成多个提供不同业务数据处理能里的数据库
- 拆表
  - 如果单表数据量过大，还可能需要对单表进行拆分
- 优点
  - 单库（单表）变小，便于管理和维护
  - 对性能和容量有提升作用
  - 改造后，系统和数据复杂度降低
  - 可以作为微服务改造的基础
- 缺点
  - 库变多，管理变复杂
  - 对业务系统有较强的侵入性
  - 改造过程复杂，容易出故障
  - 拆分到一定程度就无法继续拆分
- 垂直拆分的一般做法
  - 梳理清楚拆分范围和影响范围
  - 检查评估和重新影响到的服务
  - 准备新的数据库集群复制数据
  - 修改系统配置并发布新版上线
  - 注意：
    - 先拆分系统，还是先拆分数据库
    - 先拆分多大范围

### 3.数据库水平拆分

- 水平分库分表
- 分为，分库、分表、分库分表三类
- 有什么区别
- 数据库水平拆分
  - 水平拆分（按主键分库分表）：水平拆分就是直接对数据进行分片，有分库和分表两个具体方式，但是都只是降低单个节点数据量，但不改变数据本身的结构，这样对业务系统本身的代码逻辑来说，就不需要做特别大的改动，甚至可以基于一些中间件做到透明。
  - 水平拆分（按时间分库分表）：很多时候，数据是有时间属性的，所以自然可以按照时间维度来拆分。比如当前数据表和历史数据表，甚至按季度，按月，按天来划分不同的表。这样按照时间维度来查询数据时，就可以直接定位到当前的这个子表。
  - 问题：为什么有些DBA不建议分表，只建议分库？
- 分库还是分表，如何选择
  - 一般情况下，如果数据本身的读写压力较大，磁盘IO已经成为瓶颈，那么分库比分表要好。分库将数据分散到不同的数据库实例，使用不同的磁盘，从而可以并行提升整个集群的并行数据处理能力。相反的情况下，可以尽量多考虑分表，降低单表的数据量，从而减少单表操作的时间，同时也能在单个数据库上使用并行操作多个表来增加处理能力。
- 优点
  - 解决容量问题
  - 比垂直拆分对系统影响小
  - 部分提升性能和稳定性
- 缺点
  - 集群规模大，管理复杂
  - 复杂SQL支持问题（业务侵入性、性能）
  - 数据迁移问题
  - 一致性问题
- 数据库的分类管理
  - 通过分类处理提升数据管理能力
    - 随着对业务系统、数据本身的进一步了解，会发现很多数据对质量的要求是不同的。
    - 比如，订单数据，可能一直一致性要求最高，不能丢数据。而日志数据和一些计算的中间数据，我们则是可以不要那么高的一致性，丢了不要了，或者从别的地方找回来
    - 同样地，对于同样一张表里的订单数据，也可以采用不同策略，无效订单如果比较多，我们可以定期的清除或者转移（一些交易系统里有80%以上是机器下单然后取消的无意义订单，没有人会去查询它，所以可以清理）。
    - 如果无效订单，也可以考虑：
      - 最近一周下单但是未支付的订单，被查询和支付的可能性较大，再长时间的订单，可以直接取消掉。
      - 最近3个月下单的数据，被在线重复查询和系统统计的可能性最大
      - 超过3个月、3年以内的数据，查询的可能性非常小，可以不提供在线查询
      - 3年以上的数据，可以直接不提供任何方式的查询
    - 这样一来，就可以采取一定的手段去优化系统：
      - 定义一周内下单但未支付的数据为热数据，同时放到数据库和内存
      - 定义三个月内的数据为温数据，放到数据库，提供正常的查询操作
      - 定义3个月到3年的数据，为冷数据，从数据库删除，归档到一些便宜的磁盘，用压缩的方式（比如MySQL的tokuDB引擎，可以压缩到几十分之一）存储，用户需要邮件或者提交工单来查询，到处后发给用户
      - 定义3年以上的数据为冰数据，备份到磁带之类的介质上，不提供任何查询操作
    - 可以看到，这些都是针对一些具体场景，来分析和给出解决办法。那么通过在各种不同的场景下，都对现有的技术和手段进行一些补充，就会逐渐得到一个复杂的技术体系。

### 4.相关的框架和中间件

- Java框架层面
  - TDDL
  - Apache ShardingSphere - JDBC
- 中间件层面
  - DRDS（商业闭源）
  - Apache ShardingSphere-Proxy
  - MyCat/DBLE
  - Cobar
  - Vitness
  - KingShard
- 数据库中间件ShardingSphere
  - Apache ShardingSphere 是一套开源的分布式数据库中间件解决方案组成的生态圈，它由JDBC、Proxy和SideCar（规划中）这3款相互独立，却又能够混合部署配合使用的产品组成。它们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、云原生等各种多样化的应用场景。
  - 框架ShardingSphere-JDBC直接在业务代码使用。支持常见的数据库和JDBC。Java Only。
  - 中间件ShardingSphere-Proxy作为中间件，独立部署，对业务端透明。目前支持MySQL和PostgreSQL。任何语言平台的系统都可以接入，可以使用mysql命令或者IDE操作。对业务系统侵入性小。

### 5.如何做数据迁移

- 数据迁移是重要的一环
  - 设计新系统容易，但是我们处理的都是老系统和历史诗句
  - 怎么能更平滑的迁移旧数据到新的数据库和系统
  - 特别是在异构的数据库结构情况下
  - 达到数据准确，迁移速度快，减少停机，对业务影响小。
- 数据迁移的方式：全量
  - 全量数据导出和导入
    - 业务系统停机
    - 数据库迁移，校验一致性
    - 然后业务系统升级，接入新数据库
  - 直接复制的话，可以dump后全量导入，如果是异构数据，需要用程序来处理
- 数据迁移的方式：全量+增量
  - 依赖于数据本身的时间戳
    - 先同步数据到最近的某个时间戳
    - 然后在发布升级时停机维护
    - 再同步最后一段时间（通常是一天）的变化数据
    - 最后升级业务系统，接入新数据库
- 数据迁移的方式：binlog+全量+增量
  - 通过主库或者从库的binlog来解析和重新构造数据，实现复制
  - 一般需要中间件等工具的支持
  - 可以实现多线程，断点续传，全量历史和增量数据同步
  - 继而可以做到：
    - 实现自定义复杂异构数据结构
    - 实现自动扩容和缩容，比如分库分表到单库单表，单库单表到分库分表，分4个库表到分64个库表。
- 数据库中间件ShardingSphere
  - 迁移工具ShardingSphere-scaling
    - 支持数据全量和增量同步
    - 支持断点续传和多线程数据同步
    - 支持数据库异构复制和动态扩容
    - 具有UI界面，可视化配置

### 6.总结

